services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    network_mode: "host"
    environment:
    - OLLAMA_BASE_URL=http://127.0.0.1:11434
    volumes:
    - "${HOME}/open-webui:/app/backend/data"

  ollama:
    image: dustynv/ollama:r36.4.0
    container_name: ollama
    runtime: nvidia
    network_mode: "host"
    shm_size: "8g"
    command: ollama serve
    restart: unless-stopped
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
      - "${HOME}/data:/data"
      - "${HOME}/.ollama:/root/.ollama"
      - "/etc/localtime:/etc/localtime:ro"
      - "/etc/timezone:/etc/timezone:ro"
      - "/run/jtop.sock:/run/jtop.sock"
